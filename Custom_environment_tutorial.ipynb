{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import GYM dependencies\n",
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "#Import Helpers\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "#Import stable baselines \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Spaces ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discrete(3).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61207813, 0.73225003, 0.0434901 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0,1, shape=(3,)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([0.91728324, 0.47266385, 0.53501207], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tuple((Discrete(3), Box(0,1, shape=(3,)))).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('height': Discrete(2), 'speed': Box(0.0, 100.0, (1,), float32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict({'height':Discrete(2), \"speed\":Box(0,100,shape=(1,))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiBinary(4).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiDiscrete([5,2,2]).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Environment ##\n",
    "- Build an agent to give us the best shower possible\n",
    "- Randomly temperature\n",
    "- 37 and 39 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box(low=0, high=100, shape=(1,), dtype=np.float32)\n",
    "        self.state = 38 + random.randint(-3, 3)\n",
    "        self.shower_length = 60\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Apply temperature adjustment\n",
    "        self.state += action - 1\n",
    "\n",
    "        # Decrease shower time\n",
    "        self.shower_length -= 1\n",
    "\n",
    "        # Calculate reward\n",
    "        if 37 <= self.state <= 39:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "\n",
    "        # Check if the episode is done\n",
    "        terminated = self.shower_length <= 0\n",
    "        truncated = False  # Assuming no truncation condition in this simple environment\n",
    "        \n",
    "        info = {}\n",
    "\n",
    "        return np.array([self.state], dtype=np.float32), reward, terminated, truncated, info\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.state = 38 + random.randint(-3, 3)\n",
    "        self.shower_length = 60\n",
    "        return np.array([self.state], dtype=np.float32), {}\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ShowerEnv()\n",
    "env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54.22644], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37.], dtype=float32), {})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your custom environment\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Environment ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-52\n",
      "Episode:2 Score:-58\n",
      "Episode:3 Score:2\n",
      "Episode:4 Score:-60\n",
      "Episode:5 Score:-46\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1,episodes+1):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "\n",
    "        done = terminated or truncated\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | 0.235    |\n",
      "| time/              |          |\n",
      "|    fps             | 1368     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -0.176       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015372569 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0192       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 56           |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.000948    |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -3.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011999442 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.0836       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50.3         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -4.94        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 576          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021861377 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0685       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 53.9         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -9.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004758455 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.483      |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.9        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -1.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012704007 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | -0.106       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.3         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.000266    |\n",
      "|    value_loss           | 88.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 3.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 533         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002149141 |\n",
      "|    clip_fraction        | 0.0309      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.025       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 5.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 526          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003013377 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.0558       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.9         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -2.57e-05    |\n",
      "|    value_loss           | 98.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 3.86         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018060823 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.0902       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 57.5         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -1.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 519          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036268416 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.2         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -9.22e-05    |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 2.04         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 516          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008172719 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.106        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.3         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.000187    |\n",
      "|    value_loss           | 82.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -2.76        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027344509 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.00467      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 49.1         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    value_loss           | 93           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 2.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003517085 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.423      |\n",
      "|    explained_variance   | 0.0985      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.5        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.000777   |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 60            |\n",
      "|    ep_rew_mean          | 2.56          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 506           |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 56            |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025552785 |\n",
      "|    clip_fraction        | 0.0184        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.404        |\n",
      "|    explained_variance   | 0.0669        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 51            |\n",
      "|    n_updates            | 550           |\n",
      "|    policy_gradient_loss | 0.001         |\n",
      "|    value_loss           | 102           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 9.22         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016382379 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 51.1         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.000617    |\n",
      "|    value_loss           | 94.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 5.66         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 502          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013651102 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47.3         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.000171    |\n",
      "|    value_loss           | 86.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 5.98         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 500          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018347054 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.277        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.8         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 5.54        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002433741 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.433      |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.2        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00059    |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 8.68         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 498          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008780358 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 39.3         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.000311    |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 9.3          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 496          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022805245 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 55.1         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 93.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x26f593f6110>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_path = os.path.join('Training', 'Saved Models', 'PPO_Shower_Model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(shower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(shower_path, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 60.0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
